{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "> Understanding shape in numpy will be one of the fundamental things that allows us to begin using more powerful tools like numpy to build our NN and will be useful for debugging in the future. \n",
    "\n",
    "* [np.shape Decumentation](https://numpy.org/devdocs/reference/generated/numpy.shape.html)\n",
    "\n",
    "One way to think about shape is at each dimension whats the size? Lets begin by looking at a simple python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "list = [1,2,3,4]\n",
    "\n",
    "print(np.shape(list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You may at first think that this is a strange result. From a math point of view [1,2,3,4] looks exactly like a row vactor with 1 row and 1 column, However in numpy Arrays are treated a little different because of thier [implamentation](https://stackoverflow.com/questions/22053050/difference-between-numpy-array-shape-r-1-and-r). Because this list has only a single index we call it a 1D array which is an array with only one dimension, thus it does not make sense to talk about its second dimension. \n",
    "\n",
    "Syntatically we can add a dimension by enclosing the list in another list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n"
     ]
    }
   ],
   "source": [
    "list = np.array([[1,2,3,4]])\n",
    "\n",
    "print(np.shape(list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should start to make sense now, the outer list contains 1 element and the inner list contains 4 hence our shape is (1, 4). \n",
    "\n",
    "I encourage you to play around with this example below to see how shape changes as you add more lists and change the number of elements.\n",
    "* What happens if you remove one of the elements of the inner lists but not the other? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "list = np.array([[1,2,3,4],\n",
    "                 [1,2,3,4]])\n",
    "\n",
    "print(np.shape(list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dot Product:\n",
    "---\n",
    "\n",
    "The dot product or scaler product is an operation on vectors and matrices that returns a scaler resulting from multiplying entries element wise. The best way to learn this is with examples so lets dive in! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dotProduct: 20\n",
      "np.dot: 20\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3,4] \n",
    "b = [1,1,3,2]\n",
    "\n",
    "dotProduct = a[0]*b[0] + a[1]*b[1] + a[2]*b[2] + a[3]*b[3]\n",
    "\n",
    "print(\"dotProduct:\", dotProduct)\n",
    "\n",
    "print(\"np.dot:\", np.dot(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start applying this to our pervious example. Recall from the Basic Neuron we had:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3\n"
     ]
    }
   ],
   "source": [
    "inputs = [1, 2, 3]\n",
    "weights = [0.2, 0.8, -0.5]\n",
    "bias = 2\n",
    "\n",
    "output = inputs[0]*weights[0] + inputs[1]*weights[1] + inputs[2]*weights[2] + bias\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to clean this up with numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs shape: (3,)\n",
      "weights shape: (3,)\n",
      "2.3\n"
     ]
    }
   ],
   "source": [
    "inputs = [1, 2, 3]\n",
    "weights = [0.2, 0.8, -0.5]\n",
    "bias = 2\n",
    "\n",
    "print(\"inputs shape:\", np.shape(inputs))\n",
    "print(\"weights shape:\", np.shape(weights))\n",
    "\n",
    "\n",
    "output = np.dot(inputs, weights) + bias\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! next lets clean up the Basic layer example which looked like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "inputs = [1, 2, 3, 2.5]\n",
    "\n",
    "weights1 = [0.2, 0.8, -0.5, 1.0]\n",
    "weights2 = [0.5, -0.91, 0.26, -0.5]\n",
    "weights3 = [-0.26, -0.27, 0.17, 0.87]\n",
    "\n",
    "bias1 = 2\n",
    "bias2 = 3\n",
    "bias3 = 0.5\n",
    "\n",
    "output = [inputs[0]*weights1[0] + inputs[1]*weights1[1] + inputs[2]*weights1[2] + inputs[3]*weights1[3] + bias1,\n",
    "          inputs[0]*weights2[0] + inputs[1]*weights2[1] + inputs[2]*weights2[2] + inputs[3]*weights2[3] + bias2,\n",
    "          inputs[0]*weights3[0] + inputs[1]*weights3[1] + inputs[2]*weights3[2] + inputs[3]*weights3[3] + bias3]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, looking at this example we see that all we are doing is multiplying the first element of inputs with the first elemet of weights1, weights2, and weights3 then adding bias1 and storing that as the first entry of a list. We then repeat this processes element wise, this should feel kind of like a dot product with maybe an extra addition thrown in... Thats exactly what it is, all we need to do is create a 3x4 matrix A where the ith row is weights(i) (I encourage you to try this out by hand first and then try to code if anything is unclear). Let's see how this is done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs shape: (4,)\n",
      "weights shape: (3, 4)\n",
      "biases shape: (3,)\n"
     ]
    }
   ],
   "source": [
    "inputs = [1, 2, 3, 2.5]\n",
    "\n",
    "weights1 = [0.2, 0.8, -0.5, 1.0]\n",
    "weights2 = [0.5, -0.91, 0.26, -0.5]\n",
    "weights3 = [-0.26, -0.27, 0.17, 0.87]\n",
    "\n",
    "#Replace with a single 2D array\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "            [0.5, -0.91, 0.26, -0.5],\n",
    "            [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "bias1 = 2\n",
    "bias2 = 3\n",
    "bias3 = 0.5\n",
    "\n",
    "#Replace with a single 1D array\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "#check shapes\n",
    "print(\"inputs shape:\", np.shape(inputs))\n",
    "print(\"weights shape:\", np.shape(weights))\n",
    "print(\"biases shape:\", np.shape(biases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So this means that order now matters, hopfully you remember that for a dot product to be defined the number columns of the first object need to match the number of rows of the second. In the context of shape that means that np.dot(weights, inputs) will work because (3,4) * (4,) works out; the two inner numbers are the same, 4. Lets try this out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8   1.21  2.385]\n"
     ]
    }
   ],
   "source": [
    "inputs = [1, 2, 3, 2.5]\n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "            [0.5, -0.91, 0.26, -0.5],\n",
    "            [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "output = np.dot(weights, inputs) + biases\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Now, you should see that if we try np.dot(inputs, weights) it should give us an error because of thier shapes, namely (4,) * (3,4) the inner numbers blank (,) and 3 dont match. Lets see if we are right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (4,) and (3,4) not aligned: 4 (dim 0) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-e822c930921e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbiases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (4,) and (3,4) not aligned: 4 (dim 0) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "inputs = [1, 2, 3, 2.5]\n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "            [0.5, -0.91, 0.26, -0.5],\n",
    "            [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "output = np.dot(inputs, weights) + biases\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great you now have an understanding of the fundamentals of mechiene learning in numpy! Congratulations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
